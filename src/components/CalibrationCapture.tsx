/**
 * CalibrationCapture - ëª¨ìŒ ë³´ì • ë°ì´í„° ìº¡ì²˜ ë„êµ¬
 *
 * ì´ ì»´í¬ë„ŒíŠ¸ëŠ” ì‚¬ìš©ìê°€ ë„¤ ê°€ì§€ ê¸°ë³¸ ëª¨ìŒ(ì¤‘ë¦½, ã…, ã…œ, ã…£)ì˜
 * ì–¼êµ´ ëœë“œë§ˆí¬ì™€ ë¸”ë Œë“œì‰ì´í”„ë¥¼ ìº¡ì²˜í•˜ì—¬ vowel_calibration.jsonì— ì €ì¥í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
 */

import { useRef, useEffect, useState } from 'react';
import { FaceLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';
import { ALL_TRACKED_LANDMARKS } from '../constants/landmarks';
import { TARGET_BLENDSHAPES } from '../utils/blendshapeProcessor';
import { precomputeAllTargetVowels, saveTargetsToBackend } from '../utils/precomputeTargets';
import axios from 'axios';

interface CalibrationData {
  neutral?: CapturedFrame;
  a?: CapturedFrame;
  u?: CapturedFrame;
  i?: CapturedFrame;
}

interface CapturedFrame {
  landmarks: Record<string, [number, number, number]>;
  blendshapes: Record<string, number>;
}

const CalibrationCapture: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const faceLandmarkerRef = useRef<FaceLandmarker | null>(null);
  const animationFrameRef = useRef<number | undefined>(undefined);

  const [isInitialized, setIsInitialized] = useState(false);
  const [currentVowel, setCurrentVowel] = useState<'neutral' | 'a' | 'u' | 'i'>('neutral');
  const [calibrationData, setCalibrationData] = useState<CalibrationData>({});
  const [isCapturing, setIsCapturing] = useState(false);
  const [countdown, setCountdown] = useState<number | null>(null);
  const [isSaving, setIsSaving] = useState(false); // ì„œë²„ ì „ì†¡ì„ ìœ„í•œ ë¡œë”© state ì¶”ê°€

  useEffect(() => {
    initializeMediaPipe();
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  const initializeMediaPipe = async () => {
    try {
      const vision = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm',
      );

      const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
          delegate: 'GPU',
        },
        outputFaceBlendshapes: true,
        runningMode: 'VIDEO',
        numFaces: 1,
        minFaceDetectionConfidence: 0.5,
        minFacePresenceConfidence: 0.5,
      });

      faceLandmarkerRef.current = faceLandmarker;

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 1280, height: 720 },
      });

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play();
        setIsInitialized(true);
        startProcessing();
      }
    } catch (error) {
      console.error('Failed to initialize:', error);
    }
  };

  const startProcessing = () => {
    const processFrame = () => {
      if (videoRef.current && canvasRef.current && faceLandmarkerRef.current) {
        const video = videoRef.current;
        const canvas = canvasRef.current;
        const ctx = canvas.getContext('2d');

        if (!ctx) return;

        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // ë¹„ë””ì˜¤ ì¢Œìš° ë°˜ì „
        ctx.save();
        ctx.scale(-1, 1);
        ctx.translate(-canvas.width, 0);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        ctx.restore();

        // MediaPipeë¡œ ì²˜ë¦¬
        const results = faceLandmarkerRef.current.detectForVideo(video, performance.now());

        if (results.faceLandmarks && results.faceLandmarks.length > 0) {
          const landmarks = results.faceLandmarks[0];

          // ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
          ALL_TRACKED_LANDMARKS.forEach(index => {
            const landmark = landmarks[index];
            const x = (1 - landmark.x) * canvas.width;
            const y = landmark.y * canvas.height;

            // ì´ë§ˆì (10ë²ˆ)ì€ ë” í¬ê³  ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ í‘œì‹œ
            if (index === 10) {
              ctx.fillStyle = '#FF0000'; // ë¹¨ê°„ìƒ‰
              ctx.beginPath();
              ctx.arc(x, y, 6, 0, 2 * Math.PI);
              ctx.fill();
              // ì´ë§ˆì  ë¼ë²¨
              ctx.fillStyle = '#FFFFFF';
              ctx.font = '14px Arial';
              ctx.fillText('ì´ë§ˆ', x + 8, y - 8);
            } else {
              ctx.fillStyle = '#00FF00'; // ì´ˆë¡ìƒ‰
              ctx.beginPath();
              ctx.arc(x, y, 3, 0, 2 * Math.PI);
              ctx.fill();
            }
          });
        }
      }

      animationFrameRef.current = requestAnimationFrame(processFrame);
    };

    processFrame();
  };

  const captureFrame = async () => {
    if (!faceLandmarkerRef.current || !videoRef.current) return;

    setIsCapturing(true);

    // ì¹´ìš´íŠ¸ë‹¤ìš´
    for (let i = 3; i > 0; i--) {
      setCountdown(i);
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
    setCountdown(null);

    // ìº¡ì²˜
    const results = faceLandmarkerRef.current.detectForVideo(videoRef.current, performance.now());

    if (results.faceLandmarks && results.faceLandmarks.length > 0) {
      const landmarks = results.faceLandmarks[0];
      const blendshapes = results.faceBlendshapes?.[0]?.categories || [];

      // ëœë“œë§ˆí¬ ì¶”ì¶œ
      const capturedLandmarks: Record<string, [number, number, number]> = {};
      ALL_TRACKED_LANDMARKS.forEach(index => {
        const lm = landmarks[index];
        capturedLandmarks[index.toString()] = [lm.x, lm.y, lm.z];
      });

      // ë¸”ë Œë“œì‰ì´í”„ ì¶”ì¶œ
      const capturedBlendshapes: Record<string, number> = {};
      blendshapes.forEach((bs: any) => {
        const name = bs.categoryName || bs.displayName || '';
        if (TARGET_BLENDSHAPES.includes(name)) {
          capturedBlendshapes[name] = bs.score || 0;
        }
      });

      const frame: CapturedFrame = {
        landmarks: capturedLandmarks,
        blendshapes: capturedBlendshapes,
      };

      setCalibrationData(prev => ({
        ...prev,
        [currentVowel]: frame,
      }));

      alert(`âœ… Captured ${currentVowel}!`);
    }

    setIsCapturing(false);
  };

  const handleSaveClick = async () => {
    const calibJson = JSON.stringify(calibrationData, null, 2);
    const calibBlob = new Blob([calibJson], { type: 'application/json' });
    const calibUrl = URL.createObjectURL(calibBlob);
    const calibLink = document.createElement('a');
    calibLink.href = calibUrl;
    calibLink.download = 'vowel_calibration.json';
    calibLink.click();
    URL.revokeObjectURL(calibUrl);
    console.log('ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°±ì—… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ');

    setIsSaving(true);

    try {
      console.log('ëª¨ë“  ëª¨ìŒì˜ ëª©í‘œ ì¢Œí‘œ ê³„ì‚° ì¤‘...');
      const precomputedTargets = precomputeAllTargetVowels(calibrationData);

      // ì„ì‹œ í† í°
      const TEMP_AUTH_TOKEN =
        'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ0ZXN0SmVvbmd5ZXVuIiwiYXV0aCI6IlJPTEVfVVNFUiIsImV4cCI6MTc2MTcxNzU3MX0.1UkZWE9nwXx5lThtk0Mz0PAP5fpQ43F3ly2uQZsBd2E';

      // saveTargetsToBackend í˜¸ì¶œ
      await saveTargetsToBackend(precomputedTargets, calibrationData, TEMP_AUTH_TOKEN);

      // ì €ì¥ ì„±ê³µ
      alert(
        'Save Complete!\n\n' + 'Your calibration data has been successfully saved to the backend.',
      );
    } catch (error) {
      // axios ì—ëŸ¬ ì²˜ë¦¬
      console.error('ì„œë²„ ì „ì†¡ ë˜ëŠ” ê³„ì‚° ì‹¤íŒ¨:', error);

      let errorMessage = 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';

      if (axios.isAxiosError(error)) {
        if (error.response) {
          // ë°±ì—”ë“œ(GlobalExceptionHandler)ê°€ ë³´ë‚¸ ì‘ë‹µì´ ìˆëŠ” ê²½ìš°
          errorMessage = error.response.data.message || `ì„œë²„ ì˜¤ë¥˜: ${error.response.status}`;
        } else if (error.request) {
          // ìš”ì²­ì€ ë³´ëƒˆìœ¼ë‚˜ ì‘ë‹µì„ ë°›ì§€ ëª»í•œ ê²½ìš°
          errorMessage = 'ì„œë²„ë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.';
        } else {
          // ìš”ì²­ì„ ì„¤ì •í•˜ëŠ” ì¤‘ì— ë°œìƒí•œ ì˜¤ë¥˜
          errorMessage = error.message;
        }
      } else if (error instanceof Error) {
        errorMessage = error.message;
      }

      alert('ì„œë²„ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\n' + errorMessage);
    } finally {
      setIsSaving(false);
    }
  };

  const vowelInstructions = {
    neutral: 'ğŸ˜ Neutral face - Relax your mouth\nğŸ“ ì´ë§ˆì (ë¹¨ê°„ ì )ì´ ì˜ ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”',
    a: 'ğŸ˜® Say "ã…" (ah) - Open mouth wide\nğŸ“ ì´ë§ˆì (ë¹¨ê°„ ì )ì´ ì˜ ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”',
    u: 'ğŸ˜— Say "ã…œ" (oo) - Round and pucker lips\nğŸ“ ì´ë§ˆì (ë¹¨ê°„ ì )ì´ ì˜ ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”',
    i: 'ğŸ˜ Say "ã…£" (ee) - Spread lips wide\nğŸ“ ì´ë§ˆì (ë¹¨ê°„ ì )ì´ ì˜ ë³´ì´ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”',
  };

  return (
    <div
      style={{
        padding: '20px',
        width: '100vw',
        backgroundColor: '#ffffff',
        minHeight: '100vh',
        boxSizing: 'border-box',
      }}
    >
      <h1
        style={{ textAlign: 'center', color: '#f04299', fontSize: '2.5rem', marginBottom: '2rem' }}
      >
        Vowel Calibration Tool
      </h1>

      <div
        style={{
          display: 'flex',
          gap: '30px',
          marginTop: '20px',
          maxWidth: '1400px',
          margin: '20px auto 0',
        }}
      >
        {/* ë¹„ë””ì˜¤/ìº”ë²„ìŠ¤ */}
        <div style={{ flex: '2', minWidth: '600px' }}>
          <div
            style={{
              position: 'relative',
              width: '100%',
              aspectRatio: '16/9',
              backgroundColor: '#000',
              borderRadius: '10px',
              overflow: 'hidden',
            }}
          >
            <video
              ref={videoRef}
              style={{
                position: 'absolute',
                width: '100%',
                height: '100%',
                objectFit: 'cover',
                display: 'none',
              }}
            />
            <canvas
              ref={canvasRef}
              style={{ position: 'absolute', width: '100%', height: '100%', objectFit: 'cover' }}
            />
            {countdown !== null && (
              <div
                style={{
                  position: 'absolute',
                  top: '50%',
                  left: '50%',
                  transform: 'translate(-50%, -50%)',
                  fontSize: '120px',
                  fontWeight: 'bold',
                  color: '#00FF00',
                  textShadow: '0 0 20px rgba(0,255,0,0.8)',
                }}
              >
                {countdown}
              </div>
            )}
          </div>
        </div>

        {/* ì»¨íŠ¸ë¡¤ */}
        <div style={{ width: '450px', display: 'flex', flexDirection: 'column', gap: '20px' }}>
          <div
            style={{
              backgroundColor: '#f8f9fa',
              padding: '20px',
              borderRadius: '12px',
              boxShadow: '0 4px 12px rgba(0,0,0,0.08)',
              border: '1px solid #e9ecef',
            }}
          >
            <h3 style={{ margin: '0 0 15px 0', color: '#f04299', fontSize: '1.2rem' }}>
              Current Vowel
            </h3>
            <select
              value={currentVowel}
              onChange={e => setCurrentVowel(e.target.value as any)}
              style={{
                width: '100%',
                padding: '12px',
                fontSize: '16px',
                borderRadius: '8px',
                border: '2px solid #f04299',
                marginBottom: '10px',
              }}
            >
              <option value="neutral">Neutral (ì¤‘ë¦½)</option>
              <option value="a">ã… (ah)</option>
              <option value="u">ã…œ (oo)</option>
              <option value="i">ã…£ (ee)</option>
            </select>
            <div
              style={{
                padding: '15px',
                backgroundColor: '#ffffff',
                borderRadius: '8px',
                fontSize: '14px',
                border: '1px solid #dee2e6',
                color: '#495057',
                whiteSpace: 'pre-line',
              }}
            >
              {vowelInstructions[currentVowel]}
            </div>
          </div>

          <button
            onClick={captureFrame}
            disabled={!isInitialized || isCapturing}
            style={{
              padding: '15px 30px',
              fontSize: '18px',
              fontWeight: 'bold',
              backgroundColor: isCapturing ? '#ccc' : '#f04299',
              color: '#fff',
              border: 'none',
              borderRadius: '10px',
              cursor: isCapturing ? 'not-allowed' : 'pointer',
            }}
          >
            {isCapturing ? 'Capturing...' : `Capture ${currentVowel.toUpperCase()}`}
          </button>

          <div
            style={{
              backgroundColor: '#f8f9fa',
              padding: '20px',
              borderRadius: '12px',
              boxShadow: '0 4px 12px rgba(0,0,0,0.08)',
              border: '1px solid #e9ecef',
            }}
          >
            <h3 style={{ margin: '0 0 15px 0', color: '#f04299', fontSize: '1.2rem' }}>
              Captured Data
            </h3>
            <div style={{ display: 'flex', flexDirection: 'column', gap: '8px' }}>
              {(['neutral', 'a', 'u', 'i'] as const).map(vowel => (
                <div
                  key={vowel}
                  style={{
                    padding: '12px',
                    backgroundColor: calibrationData[vowel] ? '#e8f5e8' : '#fff3cd',
                    borderRadius: '8px',
                    display: 'flex',
                    justifyContent: 'space-between',
                    alignItems: 'center',
                    border: `1px solid ${calibrationData[vowel] ? '#c3e6c3' : '#ffeaa7'}`,
                  }}
                >
                  <span style={{ fontWeight: '600', color: '#495057' }}>{vowel}</span>
                  <span style={{ fontSize: '16px' }}>{calibrationData[vowel] ? 'âœ…' : 'â³'}</span>
                </div>
              ))}
            </div>
          </div>

          <button
            onClick={handleSaveClick}
            disabled={Object.keys(calibrationData).length < 4 || isSaving}
            style={{
              padding: '15px 30px',
              fontSize: '18px',
              fontWeight: '600',
              backgroundColor: Object.keys(calibrationData).length < 4 ? '#e9ecef' : '#28a745',
              color: Object.keys(calibrationData).length < 4 ? '#6c757d' : '#fff',
              border: 'none',
              borderRadius: '12px',
              cursor: Object.keys(calibrationData).length < 4 ? 'not-allowed' : 'pointer',
              boxShadow: '0 2px 8px rgba(0,0,0,0.1)',
              transition: 'all 0.2s ease',
            }}
          >
            Download Calibration
          </button>

          <div style={{ fontSize: '12px', color: '#6c757d', textAlign: 'center' }}>
            Tracking: {ALL_TRACKED_LANDMARKS.length} landmarks
            <br />
            (4 face + 40 mouth)
            <br />
            <span style={{ color: '#FF0000', fontWeight: 'bold' }}>â— ì´ë§ˆì (10ë²ˆ) í¬í•¨</span>
          </div>
        </div>
      </div>
    </div>
  );
};

export default CalibrationCapture;
